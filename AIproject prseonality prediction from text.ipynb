{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13868,"status":"ok","timestamp":1754305497890,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"LI4JRuvoVpqX"},"outputs":[],"source":[" import spacy\n","from joblib import Parallel, delayed\n","import time\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6183,"status":"ok","timestamp":1754305508080,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"jvNRq6CcV3R5"},"outputs":[],"source":["# Load SpaCy's English model\n","nlp = spacy.load('en_core_web_sm')\n","\n","import spacy\n","from joblib import Parallel, delayed\n","import time\n","import pandas as pd\n","\n","# Load SpaCy's English model\n","nlp = spacy.load('en_core_web_sm')\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5914,"status":"ok","timestamp":1754305735796,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"eMzvlkfHV3rl","outputId":"26a2f39b-1d3e-4850-a627-df0e80624c75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data = pd.read_csv('/content/drive/MyDrive/mbti_1.csv')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1754305740037,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"zUVE2-skYgVb","outputId":"6fd00d8f-ac5a-4348-d5ac-3dbf2346f808"},"outputs":[{"output_type":"stream","name":"stdout","text":["   type                                              posts\n","0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n","1  ENTP  'I'm finding the lack of me in these posts ver...\n","2  INTP  'Good one  _____   https://www.youtube.com/wat...\n","3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n","4  ENTJ  'You're fired.|||That's another silly misconce...\n"]}],"source":["import pandas as pd\n","print(data.head())"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2006833,"status":"ok","timestamp":1754307749599,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"q84Et7Y9YgX9","outputId":"2e46b8ba-8f70-480f-aa6a-e121dfac98fd"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8675/8675 [00:03<00:00, 2306.66it/s]\n","100%|██████████| 8675/8675 [33:18<00:00,  4.34it/s]"]},{"output_type":"stream","name":"stdout","text":["Preprocessing complete. Time (seconds): 2002.2443234920502\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import pandas as pd\n","import re\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from imblearn.over_sampling import SMOTE\n","from tqdm import tqdm\n","import spacy\n","\n","# Load SpaCy for lemmatization\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","def preprocess_text(text):\n","    # Remove links, special characters\n","    text = re.sub(r'http\\S+|www.\\S+', '', text)  # Remove URLs\n","    text = re.sub(r'[^\\w\\s]', '', text)         # Remove punctuation\n","    text = text.lower()                         # Lowercase text\n","    return text\n","\n","def lemmatize_text(text):\n","    doc = nlp(text)\n","    lemmatized = \" \".join([token.lemma_ for token in doc if not token.is_stop])\n","    return lemmatized\n","\n","# Load dataset\n","data = pd.read_csv('/content/drive/MyDrive/mbti_1.csv')\n","start = time.time()\n","\n","# Preprocess text (remove links, etc.)\n","tqdm.pandas()\n","data['preprocessed_text'] = data['posts'].progress_apply(preprocess_text)\n","\n","# Lemmatize using progress_apply\n","data['processed_text'] = data['preprocessed_text'].progress_apply(lemmatize_text)\n","\n","print(\"Preprocessing complete. Time (seconds):\", time.time() - start)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84207,"status":"ok","timestamp":1754307856179,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"qWNL0ZcuYgbf","outputId":"701b1432-5f1a-4fce-c516-d6a0711e1f05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","        ENFJ       0.55      0.61      0.57        38\n","        ENFP       0.69      0.61      0.65       135\n","        ENTJ       0.43      0.50      0.46        46\n","        ENTP       0.58      0.62      0.60       137\n","        ESFJ       0.43      0.33      0.38         9\n","        ESFP       0.00      0.00      0.00        10\n","        ESTJ       0.50      0.38      0.43         8\n","        ESTP       0.53      0.56      0.54        18\n","        INFJ       0.73      0.66      0.70       294\n","        INFP       0.71      0.76      0.73       366\n","        INTJ       0.64      0.62      0.63       218\n","        INTP       0.69      0.73      0.71       261\n","        ISFJ       0.55      0.52      0.53        33\n","        ISFP       0.58      0.52      0.55        54\n","        ISTJ       0.56      0.56      0.56        41\n","        ISTP       0.62      0.70      0.66        67\n","\n","    accuracy                           0.66      1735\n","   macro avg       0.55      0.54      0.54      1735\n","weighted avg       0.66      0.66      0.66      1735\n","\n"]}],"source":["# Vectorization\n","tfidf = TfidfVectorizer(max_features=5000)\n","X = tfidf.fit_transform(data['processed_text']).toarray()\n","y = data['type']\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, stratify=y, random_state=42\n",")\n","\n","# Balance the dataset using SMOTE\n","smote = SMOTE(random_state=42)\n","X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n","\n","# Train the model\n","model = LogisticRegression(max_iter=1000, random_state=42)\n","model.fit(X_train_balanced, y_train_balanced)\n","\n","# Evaluate the model\n","y_pred = model.predict(X_test)\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1754307923592,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"HzgWOBDNhg8u","outputId":"6de4faa9-e7a7-48b3-b15a-a64b5b703941"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input: I love deep intellectual conversations and enjoy thinking about abstract concepts.\n","Predicted Personality: INTP\n","\n","Input: I'm highly organized and like planning my tasks ahead.\n","Predicted Personality: INTJ\n","\n","Input: I enjoy socializing and trying new activities with friends.\n","Predicted Personality: ISFP\n","\n"]}],"source":["def predict_personality(input_text):\n","    processed_text = preprocess_text(input_text)  # Preprocess input\n","    vectorized_text = tfidf.transform([processed_text]).toarray()\n","    prediction = model.predict(vectorized_text)\n","    return prediction[0]\n","\n","# Test with custom input\n","test_inputs = [\n","    \"I love deep intellectual conversations and enjoy thinking about abstract concepts.\",\n","    \"I'm highly organized and like planning my tasks ahead.\",\n","    \"I enjoy socializing and trying new activities with friends.\"\n","]\n","\n","for text in test_inputs:\n","    print(f\"Input: {text}\")\n","    print(f\"Predicted Personality: {predict_personality(text)}\\n\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10602,"status":"ok","timestamp":1754307942401,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"u9HvGCHbhhKe","outputId":"c007d6ff-c81f-457f-8dad-1ce971d7a108"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ngrok\n","  Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n","Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ngrok\n","Successfully installed ngrok-1.4.0\n"]}],"source":["!pip install ngrok"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15174,"status":"ok","timestamp":1754307961386,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"cTPLMV2KhzbS","outputId":"75b4f585-27ce-4065-9057-ae1501dd2efa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.2.13-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Downloading pyngrok-7.2.13-py3-none-any.whl (25 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.2.13\n"]}],"source":["!pip install pyngrok"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1327,"status":"ok","timestamp":1754307962718,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"w74AymOqhzd0","outputId":"8a691855-b94e-491c-e4ec-a53c031758a2"},"outputs":[{"output_type":"stream","name":"stdout","text":[]}],"source":["from pyngrok import ngrok\n","\n","# Replace the string below with your actual authtoken\n","authtoken = \"2nAUp5YnDqOJPFrgKfyCjLiJOiO_6Dmdt6jWfHTruszLzii7D\"\n","ngrok.set_auth_token(authtoken)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8351,"status":"ok","timestamp":1754308181726,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"rFnBFrEyhzgk","outputId":"4635e2c5-01d2-4d1e-c2ef-2bcf94001091"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.13)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.47.1 watchdog-6.0.0\n"]}],"source":["!pip install streamlit pyngrok"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85836,"status":"ok","timestamp":1754309493167,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"LIfngiBchzjG","outputId":"5c13debe-0c5f-453a-977a-2580f5073397"},"outputs":[{"output_type":"stream","name":"stdout","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","        ENFJ       0.55      0.61      0.57        38\n","        ENFP       0.69      0.61      0.65       135\n","        ENTJ       0.43      0.50      0.46        46\n","        ENTP       0.58      0.62      0.60       137\n","        ESFJ       0.43      0.33      0.38         9\n","        ESFP       0.00      0.00      0.00        10\n","        ESTJ       0.50      0.38      0.43         8\n","        ESTP       0.53      0.56      0.54        18\n","        INFJ       0.73      0.66      0.70       294\n","        INFP       0.71      0.76      0.73       366\n","        INTJ       0.64      0.62      0.63       218\n","        INTP       0.69      0.73      0.71       261\n","        ISFJ       0.55      0.52      0.53        33\n","        ISFP       0.58      0.52      0.55        54\n","        ISTJ       0.56      0.56      0.56        41\n","        ISTP       0.62      0.70      0.66        67\n","\n","    accuracy                           0.66      1735\n","   macro avg       0.55      0.54      0.54      1735\n","weighted avg       0.66      0.66      0.66      1735\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["['personality_prediction_model.pkl']"]},"metadata":{},"execution_count":13}],"source":["# Vectorization\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Vectorization\n","tfidf = TfidfVectorizer(max_features=5000)\n","X = tfidf.fit_transform(data['processed_text']).toarray()\n","y = data['type']\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, stratify=y, random_state=42\n",")\n","\n","# Balance the dataset using SMOTE\n","smote = SMOTE(random_state=42)\n","X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n","\n","# Train the model\n","model = LogisticRegression(max_iter=1000, random_state=42)\n","model.fit(X_train_balanced, y_train_balanced)\n","\n","# Evaluate the model\n","y_pred = model.predict(X_test)\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","import joblib\n","\n","# ... (Your model training code) ...\n","\n","# Save the TF-IDF vectorizer\n","joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n","\n","# Save the trained model\n","joblib.dump(model, 'personality_prediction_model.pkl')"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1754309718648,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"},"user_tz":-300},"id":"XEdW8_n-hzlm","outputId":"b6760966-e8df-479e-bd8a-583e79ddc27b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","import streamlit as st\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import joblib\n","import numpy as np\n","\n","# Load the pre-trained model and tokenizer for personality prediction\n","# Load your TF-IDF vectorizer and trained personality prediction model (Assuming they are saved as .pkl files)\n","tfidf = joblib.load('tfidf_vectorizer.pkl')\n","model = joblib.load('personality_prediction_model.pkl')\n","\n","# Preprocessing function (Assume it's defined elsewhere)\n","def preprocess_text(text):\n","    # Implement text preprocessing logic here (lowercasing, removing stopwords, etc.)\n","    return text.lower()\n","\n","# Function to predict personality\n","def predict_personality(input_text):\n","    processed_text = preprocess_text(input_text)  # Preprocess input\n","    vectorized_text = tfidf.transform([processed_text]).toarray()\n","    prediction = model.predict(vectorized_text)\n","    return prediction[0]\n","\n","# Streamlit UI\n","st.title(\"Personality Predictor\")\n","user_input = st.text_area(\"Enter text to predict personality:\")\n","\n","if st.button(\"Predict Personality\"):\n","    if user_input.strip():  # Ensure the input is not empty\n","        prediction = predict_personality(user_input)\n","        st.write(f\"Predicted Personality: {prediction}\")\n","    else:\n","        st.write(\"Please enter some text to predict personality.\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"KpnCi2fUhzpB","executionInfo":{"status":"ok","timestamp":1754309724099,"user_tz":-300,"elapsed":411,"user":{"displayName":"Ayesha Imran","userId":"18358817385351129759"}}},"outputs":[],"source":["from pyngrok import ngrok\n","\n","# List all active tunnels\n","tunnels = ngrok.get_tunnels()\n","\n","# Disconnect each tunnel\n","for tunnel in tunnels:\n","    ngrok.disconnect(tunnel.public_url)\n","    print(f\"Disconnected tunnel: {tunnel.public_url}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"SpzrwgH2iVw9","outputId":"11cf212d-8a83-4750-b9a4-77c87aef4063"},"outputs":[{"output_type":"stream","name":"stdout","text":["Streamlit app URL: https://a91dbba995f3.ngrok-free.app\n"]}],"source":["import subprocess\n","from pyngrok import ngrok\n","\n","# Start the ngrok tunnel\n","# Specify tunnel type and port explicitly\n","tunnel = ngrok.connect(addr=\"8501\", bind_tls=True)\n","print(\"Streamlit app URL:\", tunnel.public_url)\n","\n","# Run the Streamlit app\n","subprocess.run([\"streamlit\", \"run\", \"app.py\"])"]}],"metadata":{"colab":{"provenance":[{"file_id":"1PFul_gQpCft89lPGbdEILPe7WdncKWDq","timestamp":1736621626511}],"authorship_tag":"ABX9TyM/yLPtTvQbZpCfX+tKhB6E"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}